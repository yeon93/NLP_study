{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PQSnsGeA2OH"
      },
      "source": [
        "# 트랜스포머 (Transformer)\n",
        "\n",
        "* 참고: https://wikidocs.net/31379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbQ-h_XxBAiq"
      },
      "source": [
        "* attention 매커니즘은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n",
        "* attention 매커니즘을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n",
        "* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n",
        "\n",
        "#### 트랜스포머의 구조\n",
        "+ 트랜스포머는 인코더-디코더가 6개씩 모여있는 구조이다.\n",
        "+ 각각의 인코더, 디코더 블록이 학습하는 파라미터는 독립적이다.\n",
        "+ 각 인코더 블록은 2개의 sub-layer로 구성\n",
        "  + Multi-head (self) attention\n",
        "    + 입력된 문장 내부 요소의 관계를 파악하는 부분이다.\n",
        "    + Self-Attention을 동시에 병렬적으로 실행하며, 각 Head마다 다른 Attention 결과값을 내어주기 때문에, 앙상블과 유사한 효과를 얻을 수 있다.\n",
        "  + Feed Forward\n",
        "+ 각 디코더 블록은 3개의 sub-layer로 구성\n",
        "  + Masked Multi-head (self) attention\n",
        "    + 디코더는 Auto-Regressive(왼쪽 단어를 보고 오른쪽 단어를 예측하는) 방법으로 단어를 생성하기 때문에, 타겟 단어 뒤에 위치한 단어가 Self-Attention에 영향을 주지 않도록 마스킹\n",
        "    + softmax를 취하기 전, 마스킹할 요소에  (-무한대)에 해당하는 매우 작은 수를 더해주며, 마스킹된 값은 softmax를 취한 후에는 0이 되므로 v 계산에 반영되지 않는다.\n",
        "  + Multi-head (Encoder-Decoder) attention \n",
        "    + 번역 전/후 문장의 정보 관계를 연결해주는 부분\n",
        "    + 디코더 블록의 Masked Multi-Head (Self) Attention에서 출력된 벡터를 q로 사용\n",
        "    + k, v는 최상위(=6번째) 인코더 블록에서 사용했던 값을 그대로 사용\n",
        "  + Feed Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDiFPIdUBBS2"
      },
      "source": [
        "## 포지셔널 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqHf_4SEWoa"
      },
      "source": [
        "+ RNN 기반 모델은 단어가 순서대로 들어오기 때문에, 문장이 길어질수록 연산 시간이 길어진다는 단점이 있었다.\n",
        "+ 트랜스포머는 이런 문제를 해결하기 위해 모든 토큰을 동시에 입력받아 병렬연산한다. \n",
        "+ 이 때 컴퓨터는 단어의 순서를 알 수 없기 때문에, **단어의 위치 정보를 제공하기 위한 벡터**를 따로 제공해줘야 한다.  \n",
        "=> `Positional Encoding` (인코딩-디코딩 모두에서 수행, sin/cos 함수 이용)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiO5c_HIFBAk"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def positional_encoding(dim, len_sentence):\n",
        "  encoded_vec = np.array([position / np.power(10000, 2*i/dim) for position in range(len_sentence) for i in range(dim)])\n",
        "  encoded_vec[::2] = np.sin(encoded_vec[::2])    #홀수 인덱스인 값들에 대해 sin \n",
        "  encoded_vec[1::2] = np.cos(encoded_vec[1::2])  #짝수 인덱스인 값들에 대해 cos \n",
        "  \n",
        "  return tf.constant(encoded_vec.reshape([len_sentence, dim]), dtype=tf.float32)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099gUUxhAgy3"
      },
      "source": [
        "## 레이어 정규화(Layer normalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdips98yPuH"
      },
      "source": [
        "+ 트랜스포머의 모든 sub-layer에서 출력된 벡터는 Layer normalization과 Skip connection을 거치게 된다.\n",
        "+ 레이어 정규화는 batch normalization과 유사하며, 학습이 훨씬 빠르고 잘 되도록 한다.\n",
        "+ 레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화\n",
        "+ 해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJjxF86Aeg3"
      },
      "source": [
        "def layer_norm(inputs, eps=1e-6):\n",
        "  feature_shape = inputs.get_shape()[-1:]\n",
        "  mean = tf.keras.backend.mean(inputs, [-1], keepdims=True)\n",
        "  std = tf.keras.backend.std(inputs, [-1], keepdims=True)\n",
        "  beta = tf.Variable(tf.zeros(feature_shape), trainable=False)\n",
        "  gamma = tf.Variable(tf.ones(feature_shape), trainable=False)\n",
        "\n",
        "  return gamma * (inputs-mean) / (std+eps) + beta   #featur shape로 모양 맞추기"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km9ORxIun-MU"
      },
      "source": [
        "def sublayer_connection(inputs, sublayer, dropout=0.2):\n",
        "  outputs = layer_norm(inputs + tf.keras.layers.Dropout(dropout)(sublayer))\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppb7IxJ3diMC"
      },
      "source": [
        "## 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaU6MHgy9V2"
      },
      "source": [
        "*   트랜스포머 모델의 핵심이 되는 부분\n",
        "*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n",
        "  1.   multi-head attention\n",
        "      + 입력된 문장 내부 요소의 관계를 파악하는 부분\n",
        "      + self attention을 동시에 병렬적으로 실행하며, 각 head마다 다른 attention결과값을 내어주기 때문에, 앙상블과 유사한 효과\n",
        "      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n",
        "      * 마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n",
        "      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n",
        "  2.   self attention\n",
        "      * 일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n",
        "      * 이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n",
        "      * 반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n",
        "      * 이는 입력 문장 내 단어간의 어텐션을 의미함\n",
        "      + 즉, 인코더에서 입력받은 문장 내부 요소의 관계를 잘 파악하기 위해서, 문장 자신에 대해 Attention 매커니즘을 적용하는 것이다.\n",
        "      + 기존 attention과 달리, query, key, value 모두 인코더에서 얻음\n",
        "      + query : 분석하고자 하는 단어에 대한 가중치 벡터\n",
        "      + key : 각 단어가 query와 얼마나 연관있는지 비교하기 위한 가중치 벡터\n",
        "      + value : 각 단어의 의미를 살려주기 위한 가중치 벡터\n",
        "\n",
        "\n",
        "*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRyL0KDXi6ej"
      },
      "source": [
        "### scaled-dot product attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HtmcgRR3Cr-"
      },
      "source": [
        "* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n",
        "* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n",
        "* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALEMzi4fdiSQ"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, masked=False):   #attention 가중치를 구하는 함수\n",
        "  key_dim_size = float(key.get_shape().as_list()[-1])\n",
        "  key = tf.transpose(key, perm=[0, 2, 1])\n",
        "\n",
        "  outputs = tf.matmul(query, key) / tf.sqrt(key_dim_size)   #query, key의 내적을 key_dim_size의 제곱근으로 scaling\n",
        "\n",
        "  if masked:\n",
        "    diag_vals = tf.ones_like(outputs[0, :, :])\n",
        "    tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()    #삼각행렬\n",
        "    masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1])\n",
        "    paddings = tf.ones_like(masks) * (-2**30)   #매우 작은수(어떤 수에든 더하면 음수가 될 정도로) => padding된 값이 softmax를 통과하면 0이 되어 value 계산에 반영되지 않도록\n",
        "    outputs = tf.where(tf.equal(masks, 0), paddings, outputs)    #masks 값이 0이라면 아주 작은 값을 더해주고, 그렇지 않으면 outputs 그대로 사용\n",
        "\n",
        "  attention_map = tf.nn.softmax(outputs)    #디코더의 최상층을 통과한 벡터(outputs)는 Linear 층을 지난 후, softmax를 통해 예측 단어의 확률을 구함\n",
        "\n",
        "  return tf.matmul(attention_map, value)   #softmax취한 결과와 value를 내적"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr20BxvVi-8b"
      },
      "source": [
        "### multi-head attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb5qflUH14-H"
      },
      "source": [
        "* multi-head attention의 구현 과정\n",
        "  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n",
        "  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n",
        "  3. 분리한 행렬들에 대해 각각 어텐션을 병렬 수행\n",
        "  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooc3FAdQi_Gz"
      },
      "source": [
        "def multi_head_attention(query, key, value, num_units, heads, masked=False):\n",
        "  query = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(query)\n",
        "  key = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(key)\n",
        "  value = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(value)\n",
        "\n",
        "  query = tf.concat(tf.split(query, heads, axis=-1), axis=0)   #heads 값만큼 split하고, 각각 concat\n",
        "  key = tf.concat(tf.split(key, heads, axis=-1), axis=0)\n",
        "  value = tf.concat(tf.split(value, heads, axis=-1), axis=0)\n",
        "\n",
        "  attention_map = scaled_dot_product_attention(query, key, value, masked)\n",
        "  attention_outputs = tf.concat(tf.split(attention_map, heads, axis=0), axis=-1)\n",
        "  attention_outputs = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(attention_outputs)\n",
        "\n",
        "  return attention_outputs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Zn5-fYITD4"
      },
      "source": [
        "## 포지션-와이즈 피드 포워드 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxeG2xvo3ZN"
      },
      "source": [
        "+ 은닉층의 차원이 늘어났다가 다시 원래 차원으로 줄어드는 단순한 2층 신경망\n",
        "* multi-head attention의 결과인 행렬을 입력받아 연산\n",
        "* 일반적인 완전 연결 신경망(Dense layer)를 사용하며, 활성화 함수 ReLU 사용\n",
        "* position-wise FFNN은 인코더와 디코더에 모두 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tSFd5OaITJ0"
      },
      "source": [
        "def feed_forward(inputs, num_units):\n",
        "  feature_shape = inputs.get_shape()[-1]\n",
        "  inner_layer = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(inputs)\n",
        "  outputs = tf.keras.layers.Dense(feature_shape)(inner_layer)\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def FFNN(d_model, dff):     #d_model(모델의 차원), dff(은닉층의 차원 수. 논문에서는 2048 사용)\n",
        "#    return tf.keras.Sequential([tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "#                                tf.keras.layers.Dense(d_model)])  # (batch_size, seq_len, d_model)"
      ],
      "metadata": {
        "id": "DAisVPC02ilM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuccViYgBK6v"
      },
      "source": [
        "## 인코더\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG3MH0n1JVLz"
      },
      "source": [
        "* 인코더는 하나의 어텐션을 사용\n",
        "  + encoder self-attention (multi-head self-attention과 동일)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5T0pzBoAnn3"
      },
      "source": [
        "def encoder_module(inputs, model_dim, ffn_dim, heads):\n",
        "  self_attention = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads))\n",
        "  outputs = sublayer_connection(self_attention, feed_forward(self_attention, ffn_dim))\n",
        "\n",
        "  return outputs\n",
        "\n",
        "def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n",
        "  outputs = inputs\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_module(outputs, model_dim, ffn_dim, heads)\n",
        "\n",
        "  return outputs                         "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcgHRcTEBQqg"
      },
      "source": [
        "## 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNj-6FLQwT4-"
      },
      "source": [
        "* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n",
        "  1. masked decoder self-attention\n",
        "  2. encoder-decoder attention\n",
        "  3. position-wise FFNN\n",
        "\n",
        "* 디코더에서는 2종류의 어텐션을 사용\n",
        "  1.   masked decoder self-attention\n",
        "    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n",
        "    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n",
        "    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n",
        "  2.   encoder-decoder attention\n",
        "    *   앞서 설명한 multi-head attention과 동일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B05wr7aARcT"
      },
      "source": [
        "def decoder_module(inputs, encoder_outputs, model_dim, ffn_dim, heads):\n",
        "  masked_self_attention = sublayer_connection(inputs, \n",
        "                                              multi_head_attention(inputs, inputs, inputs, model_dim, heads, masked=True))\n",
        "  self_attention = sublayer_connection(masked_self_attention,\n",
        "                                       multi_head_attention(masked_self_attention, encoder_outputs, encoder_outputs, model_dim, heads))\n",
        "  outputs = sublayer_connection(self_attention, feed_forward(self_attention, ffn_dim))\n",
        "\n",
        "  return outputs\n",
        "\n",
        "def decoder(inputs, encoder_outputs, model_dim, ffn_dim, heads, num_layers):\n",
        "  outputs = inputs\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_module(outputs, encoder_outputs, model_dim, ffn_dim, heads)\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtztlyUB1ERS"
      },
      "source": [
        "## 트랜스포머를 활용한 챗봇"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CGUIAzv6eWs"
      },
      "source": [
        "### konlpy 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae0mHT49v5gy"
      },
      "source": [
        "*    한글을 처리하기 위해 konlpy 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yf75uG6hBW",
        "outputId": "c297e063-3b96-41c9-ce21-f0cfa89e9a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.0 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUMXvK5H1G9H"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miXrjR316mNb"
      },
      "source": [
        "* 처리에 필요한 각종 변수 선언\n",
        "* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMjn5PfE1GZR"
      },
      "source": [
        "import re\n",
        "\n",
        "filters = '([~.,!?\"\\':;)(])'\n",
        "PAD = '<PADDING>'\n",
        "STD = '<START>'\n",
        "END = '<END>'\n",
        "UNK = '<UNKNOWN>'\n",
        "\n",
        "PAD_INDEX, STD_INDEX, END_INDEX, UNK_INDEX = 0, 1, 2, 3\n",
        "\n",
        "MARKER = [PAD, STD, END, UNK]\n",
        "CHANGE_FILTER = re.compile(filters)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmRFuH2r6oNJ"
      },
      "source": [
        "* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrmdXkePWYb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(path):\n",
        "  df = pd.read_csv(path, header=0)\n",
        "  question, answer = list(df['Q']), list(df['A'])\n",
        "  x_train, x_test, y_train, y_test = train_test_split(question, answer, test_size=0.2, shuffle=True, random_state=2)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHuOJHPtPXqq"
      },
      "source": [
        "* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQL-AP06oSa"
      },
      "source": [
        "def load_vocab(path):\n",
        "  df = pd.read_csv(path, encoding='utf-8')\n",
        "  question, answer = list(df['Q']), list(df['A'])\n",
        "  if tokenize_as_morph:\n",
        "    question = prepro_like_morphlized(question)\n",
        "    answer = prepro_like_morphlized(answer)\n",
        "\n",
        "  data = []\n",
        "  data.extend(question)\n",
        "  data.extend(answer)\n",
        "  \n",
        "  words = data_tokenizer(data)\n",
        "  words = list(set(words))  #중복제거\n",
        "  words[:0] = MARKER\n",
        "\n",
        "  char2idx = {char:idx for idx, char in enumerate(words)}\n",
        "  idx2char = {idx:char for idx, char in enumerate(words)}\n",
        "\n",
        "  return char2idx, idx2char, len(char2idx)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wYtpjv76r5q"
      },
      "source": [
        "* 문자열 데이터를 학습에 사용될 수 있도록 변형하는 `prepro_like_morphlized()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQ3FOva6tg6"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "def prepro_like_morphlized(data):\n",
        "  morph_analyzer = Okt()\n",
        "  result = list()\n",
        "  for seq in data:\n",
        "    morphlized_seq = ' '.join(morph_analyzer.morphs(seq.replace(' ','')))\n",
        "    result.append(morphlized_seq)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhsVp4pWPTR3"
      },
      "source": [
        "* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otLI_RUfPR_g"
      },
      "source": [
        "def data_tokenizer(data):\n",
        "  words = []\n",
        "  for sequence in data:\n",
        "    sentence = re.sub(CHANGE_FILTER, '', sequence)\n",
        "    for word in sentence.split():\n",
        "      words.append(word)\n",
        "  \n",
        "  return [word for word in words if word]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkKPA-Mx6uaC"
      },
      "source": [
        "* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-yeSThPGsa"
      },
      "source": [
        "def enc_processing(value, dictionary):\n",
        "  sequences_input_index = []\n",
        "  sequences_length = []\n",
        "\n",
        "  if tokenize_as_morph:   #형태소 분석이 필요하면\n",
        "    value = prepro_like_morphlized(value)\n",
        "\n",
        "  for sequence in value:\n",
        "    sequence = re.sub(CHANGE_FILTER, '', sequence)\n",
        "    sequence_index = []\n",
        "    for word in sequence.split():\n",
        "      if dictionary.get(word) is not None:\n",
        "        sequence_index.extend([dictionary[word]])\n",
        "      else:\n",
        "        sequence_index.extend([dictionary[UNK]])\n",
        "\n",
        "    if len(sequence_index) > max_len:\n",
        "      sequence_index = sequence_index[:max_len]\n",
        "      \n",
        "    sequences_length.append(len(sequence_index))\n",
        "    sequence_index += (max_len-len(sequence_index)) * [dictionary[PAD]]\n",
        "    sequences_input_index.append(sequence_index)\n",
        "\n",
        "  return np.asarray(sequences_input_index), sequences_length"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mM57_FPIg7"
      },
      "source": [
        "* decoder의 입력을 구성하기 위한 함수 `dec_output_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_NpcTq6vw6"
      },
      "source": [
        "def dec_output_processing(value, dictionary):\n",
        "  sequences_output_index = []\n",
        "  sequences_length = []\n",
        "\n",
        "  if tokenize_as_morph:  \n",
        "    value = prepro_like_morphlized(value)\n",
        "\n",
        "  for sequence in value:\n",
        "    sequence = re.sub(CHANGE_FILTER, '', sequence)\n",
        "    sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]  #추가됨\n",
        "\n",
        "    if len(sequence_index) > max_len:\n",
        "      sequence_index = sequence_index[:max_len]\n",
        "\n",
        "    sequences_length.append(len(sequence_index))\n",
        "    sequence_index += (max_len-len(sequence_index)) * [dictionary[PAD]]\n",
        "    sequences_output_index.append(sequence_index)\n",
        "\n",
        "  return np.asarray(sequences_output_index), sequences_length"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otsTEt4FPLJX"
      },
      "source": [
        "* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeP0PWHEPMma"
      },
      "source": [
        "def dec_target_processing(value, dictionary):\n",
        "  sequences_target_index = []\n",
        "\n",
        "  if tokenize_as_morph:  \n",
        "    value = prepro_like_morphlized(value)\n",
        "\n",
        "  for sequence in value:\n",
        "    sequence = re.sub(CHANGE_FILTER, '', sequence)\n",
        "    sequence_index = [dictionary[word] for word in sequence.split()] \n",
        "\n",
        "    if len(sequence_index) >= max_len:\n",
        "      sequence_index = sequence_index[:max_len-1] + [dictionary[END]]\n",
        "    else:\n",
        "      sequence_index += [dictionary[END]]\n",
        "\n",
        "    sequence_index += (max_len-len(sequence_index)) * [dictionary[PAD]]\n",
        "    sequences_target_index.append(sequence_index)\n",
        "\n",
        "  return np.asarray(sequences_target_index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9vVUng6xDq"
      },
      "source": [
        "* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n",
        "* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n",
        "* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlKV4xF62Uf"
      },
      "source": [
        "from tensorflow._api.v2.compat.v1.data import make_one_shot_iterator\n",
        "\n",
        "def train_input_fn(train_input_enc, train_output_enc, train_target_dec, batch_size):\n",
        "  dataset = tf.compat.v1.data.Dataset.from_tensor_slices((train_input_enc, train_output_enc, train_target_dec))\n",
        "  dataset = dataset.shuffle(buffer_size=len(train_input_enc))\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.map(rearrange)\n",
        "  dataset = dataset.repeat()\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  return iterator.get_next()\n",
        "\n",
        "def eval_input_fn(eval_input_enc, eval_output_enc, eval_target_dec, batch_size):\n",
        "  dataset = tf.compat.v1.data.Dataset.from_tensor_slices((eval_input_enc, eval_output_enc, eval_target_dec))\n",
        "  dataset = dataset.shuffle(buffer_size=len(eval_input_enc))\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.map(rearrange)\n",
        "  dataset = dataset.repeat(1)\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  return iterator.get_next()\n",
        "\n",
        "def rearrange(input, output, target):\n",
        "  features = {'input':input, 'output':output}\n",
        "  return features, target"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is-GhUDN62xC"
      },
      "source": [
        "* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n",
        "* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfwWXhb64Cc"
      },
      "source": [
        "def pred2string(value, dictionary):\n",
        "  sentence_string = []\n",
        "  is_finished = False\n",
        "\n",
        "  for v in value:\n",
        "    sentence_string = [dictionary[index] for index in v['indexs']]\n",
        "\n",
        "  answer = ''\n",
        "  for word in sentence_string:\n",
        "    if word == END:\n",
        "      if_finished = True\n",
        "      break\n",
        "    \n",
        "    if word != PAD and word != END:\n",
        "      answer += word\n",
        "      answer += ' '\n",
        "\n",
        "  return answer, is_finished"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwp9Nnwz7UoG"
      },
      "source": [
        "* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\n",
        "* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T536MdU7Taq"
      },
      "source": [
        "tokenize_as_morph = True\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv'\n",
        "\n",
        "char2idx, idx2char, len_vocab = load_vocab(path)\n",
        "x_train, x_test, y_train, y_test = load_data(path)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train),len(y_train), len(x_test), len(y_test))\n",
        "x_train[:3], y_train[:3], x_test[:3], y_test[:3]"
      ],
      "metadata": {
        "id": "fsPacSW6LkWq",
        "outputId": "bca2f3eb-d3d5-4b19-c36d-055d2c0f6746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9458 9458 2365 2365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['도시락 싸볼까', '버스 멀미나', '고백하고 후회하면 어떡하지'],\n",
              " ['쉬운 일이 아니에요.', '핸드폰 만지지 마세요.', '후회는 후회를 낳을뿐이에요. 용기 내세요.'],\n",
              " ['위안이 됩니다', '이런 글귀가 있네', '손수건 가지고 다닐걸'],\n",
              " ['그렇게 말해주시니 제가 기분이 좋네요.', '저도 알려주세요.', '이제 그러면 돼요.'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cVd7AOKinqn"
      },
      "source": [
        "### 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqLJ0a6r49yi"
      },
      "source": [
        "* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNeeXoZginvj"
      },
      "source": [
        "import tensorflow as tf\n",
        "def model(features, labels, mode, params):\n",
        "  TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "  EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "  PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "\n",
        "  position_encode = positional_encoding(params['embedding_size'], params['max_len'])\n",
        "  if params['xavier_initializer']:\n",
        "    embedding_initializer = 'glorot_normal'\n",
        "  else:\n",
        "    embedding_initializer = 'uniform'\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(params['len_vocab'],\n",
        "                                        params['embedding_size'],\n",
        "                                        embeddings_initializer=embedding_initializer)\n",
        "  \n",
        "  x_embedded_matrix = embedding(features['input']) + position_encode\n",
        "  y_embedded_matrix = embedding(features['output']) + position_encode\n",
        "\n",
        "  encoder_outputs = encoder(x_embedded_matrix, params['model_hidden_size'], params['ffn_hidden_size'],\n",
        "                            params['attention_head_size'], params['layer_size'])\n",
        "  decoder_outputs = decoder(y_embedded_matrix, encoder_outputs, params['model_hidden_size'], params['ffn_hidden_size'],   #encoder_outputs 추가됨\n",
        "                            params['attention_head_size'], params['layer_size'])\n",
        "  \n",
        "  logits = tf.keras.layers.Dense(params['len_vocab'])(decoder_outputs)\n",
        "  predict = tf.argmax(logits, 2)\n",
        "\n",
        "  if PREDICT:\n",
        "    predictions = {'indexs':predict, 'logits':logits}\n",
        "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  labels_ = tf.one_hot(labels, params['len_vocab'])\n",
        "  loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels_))\n",
        "  accuracy = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predict)\n",
        "\n",
        "  metrics = {'accuracy':accuracy}\n",
        "  tf.summary.scalar('accuracy', accuracy[1])\n",
        "\n",
        "  if EVAL:\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
        "  assert TRAIN\n",
        "\n",
        "  optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "  train_op = optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7PrLEWE1JCs"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy_Opm_A7DKC"
      },
      "source": [
        "*   필요한 각종 인자들을 설정\n",
        "*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGYuqmH6_kj"
      },
      "source": [
        "max_len = 25\n",
        "epoch = 5000\n",
        "batch_size = 256\n",
        "embedding_size = 100\n",
        "model_hidden_size = 100\n",
        "ffn_hidden_size = 100\n",
        "attention_head_size = 100\n",
        "lr = 0.001\n",
        "layer_size = 3\n",
        "xavier_initializer = True"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaXalEy57ODq"
      },
      "source": [
        "*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n",
        "*   평가 데이터에도 동일하게 가공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlgWWIq1KSh"
      },
      "source": [
        "train_input_enc, train_input_enc_length = enc_processing(x_train, char2idx)\n",
        "train_output_dec, train_output_dec_length = dec_output_processing(y_train, char2idx)\n",
        "train_target_dec = dec_target_processing(y_train, char2idx)\n",
        "\n",
        "eval_input_enc, eval_input_enc_length = enc_processing(x_test, char2idx)\n",
        "eval_output_dec, eval_output_dec_length = dec_output_processing(y_test, char2idx)\n",
        "eval_target_dec = dec_target_processing(y_test, char2idx)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZGgZzWs7Mr7"
      },
      "source": [
        "* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n",
        "* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9vjc3Ck7F4J",
        "outputId": "1a871cdd-0abe-4226-927f-9a20ba589e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transformer = tf.estimator.Estimator(model_fn=model,\n",
        "                                     params={'embedding_size':embedding_size,\n",
        "                                             'model_hidden_size':model_hidden_size,\n",
        "                                             'ffn_hidden_size':ffn_hidden_size,\n",
        "                                             'attention_head_size':attention_head_size,\n",
        "                                             'learning_rate':lr,\n",
        "                                             'len_vocab':len_vocab,\n",
        "                                             'layer_size':layer_size,\n",
        "                                             'max_len':max_len,\n",
        "                                             'xavier_initializer':xavier_initializer})"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpatmi8mpm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl_pwUiw7INZ"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COO-0PcS7Hy5",
        "outputId": "ca7c215d-b464-4b81-ccbd-ff48ddd878f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transformer.train(input_fn=lambda: train_input_fn(train_input_enc, train_output_dec, train_target_dec, batch_size), steps=epoch)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From <ipython-input-20-360c9dd2aa03>:9: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7fa3d333e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = transformer.evaluate(input_fn=lambda: eval_input_fn(eval_input_enc, eval_output_dec, eval_target_dec, batch_size))\n",
        "\n",
        "print('accuracy : {accuracy: 0.3f}'.format(**eval_result))"
      ],
      "metadata": {
        "id": "XqN5RYFHIZxY",
        "outputId": "7398ad0a-5a7e-413b-bdbd-25e355d9ae21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy :  0.869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNcrVf2z1LSM"
      },
      "source": [
        "### 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5lY9DrW8eSK"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9IQaBx4Qw8J"
      },
      "source": [
        "def chatbot(question):\n",
        "  pred_input_enc, pred_input_enc_length = enc_processing([question], char2idx)\n",
        "  pred_output_dec, pred_output_dec_length = dec_output_processing([''], char2idx)\n",
        "  pred_target_dec = dec_target_processing([''], char2idx)\n",
        "\n",
        "  for i in range(max_len):\n",
        "    if i > 0:\n",
        "      pred_output_dec, pred_output_dec_length = dec_output_processing([answer], char2idx)\n",
        "      pred_target_dec = dec_target_processing([answer], char2idx)\n",
        "\n",
        "    predictions = transformer.predict(input_fn=lambda: eval_input_fn(pred_input_enc, pred_output_dec, pred_target_dec, batch_size=1))\n",
        "\n",
        "    answer, finished = pred2string(predictions, idx2char)\n",
        "\n",
        "    if finished:\n",
        "      break\n",
        "\n",
        "  return answer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjHZKvJ31MAU",
        "outputId": "6a170657-b80f-4b05-a818-6909459f6e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chatbot('나랑 놀아줘.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'혼자 도 좋아요 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mjRZwyLQ_gP",
        "outputId": "b6abf527-b743-415c-def3-6e7e7d279414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chatbot('내일 날씨는 어때?')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'날씨 어플 에 물어보세요 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7AJCsXRTqJx",
        "outputId": "37c7ab17-0f70-4718-c2a8-0afae984b5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chatbot('놀러 가고 싶다.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'저 도 요 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M8mfoUfeAWQ",
        "outputId": "42ddaa43-db42-47e5-e416-e58167367b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chatbot('뭐 재밌는 거 없어?')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'거울 을 보면서 얼굴 망 가 뜨 리기 놀이 해보신 적있으세요 의외로 재미있어요 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5mrdGRaem6v",
        "outputId": "dd8b9de7-cd96-406d-dd74-c4932e883ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chatbot('이제 그만 자러 갈래.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'저 는 좋아요 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}
